# The $1.2M Sora 2 Neural Director: Complete Hiring & Training Package

**Position:** Principal Neural Cinematics Director
**Compensation:** $1.2M Base + Equity + Compute Resources
**Clearance Level:** 6 (Model Weights & Architecture Access)
**Rarity:** Top 0.001% Global Talent

---

## EXECUTIVE SUMMARY

This document outlines the complete recruitment, evaluation, and onboarding protocol for the world's premier Sora 2 Prompt Architect. This is not a "Prompt Engineer" role‚Äîthis is a **Principal Neural Director** who replaces an entire VFX department with their brain and keyboard.

**The Mission:** Zero-shot fidelity. First-try perfection. No regenerations. No iterations. Mathematical precision applied to stochastic art.

---

## PART I: THE COMPLETE JOB DESCRIPTION

### THE MANDATE

We seek a singular operator capable of **high-dimensional latent space navigation**‚Äîsomeone who doesn't just prompt AI, but performs computational cinematography at a neural architecture level.

You will be the human governor of a stochastic diffusion model, forcing probabilistic mathematics to adhere to deterministic laws of cinema and physics.

---

### THE "PENTAGONAL" KNOWLEDGE DOMAIN

The successful candidate must demonstrate **mastery across five distinct disciplines:**

#### 1. NEURAL ARCHITECTURE & DEEP LEARNING THEORY

**Required Knowledge:**
- **Diffusion Transformer (DiT) Architecture:** Understanding how Sora patches video data spatially and temporally
- **Attention Mechanisms:** Ability to manipulate Q, K, V matrices through syntax hierarchy
- **Latent Space Topology:** Perform vector arithmetic on style embeddings (Style A - Feature B + Feature C = Style D)
- **Tokenization Logic:** Deep understanding of CLIP/T5 text encoders and how compound nouns are vectorized
- **Classifier-Free Guidance:** Mathematical understanding of guidance scales and their impact on adherence vs. creativity

**Testable Concepts:**
- Explain how cross-attention layers lock temporal consistency
- Describe the mathematical difference between DDPM and DDIM samplers
- Map a visual concept to its approximate position in 768-dimensional embedding space
- Explain how to use negative embeddings to subtract specific visual features

**Key Resources:**
- Papers: "Denoising Diffusion Probabilistic Models" (Ho et al.)
- Papers: "Attention Is All You Need" (Vaswani et al.)
- PyTorch/TensorFlow mastery for custom loss functions

---

#### 2. COMPUTATIONAL PHYSICS & SIMULATION ENGINEERING

**Required Knowledge:**

**Fluid Dynamics:**
- Navier-Stokes equations (conceptual understanding)
- Lagrangian vs. Eulerian simulation frameworks
- Reynolds numbers and their impact on flow behavior
- Surface tension, viscosity, and capillary action
- Caustics, refraction, and light transport through volumetric media

**Material Science:**
- BRDF (Bidirectional Reflectance Distribution Function) models
- Fresnel equations for dielectric vs. conductive materials
- Subsurface scattering profiles (skin, wax, marble, translucent materials)
- Anisotropic reflection (brushed metal, hair, fabric weave)
- Index of Refraction (IOR) for different materials

**Thermodynamics:**
- Black-body radiation for fire/heat visualization
- Thermal updrafts and pyroclastic flow behavior
- Heat shimmer and atmospheric distortion

**Rigid Body & Soft Body Dynamics:**
- Inertia, momentum, and mass distribution
- Collision response and deformation
- Cloth simulation (drape, billow, tension)
- Joint mechanics and skeletal constraints

**Testable Concepts:**
- Describe honey at 10¬∞C vs. 80¬∞C using only physics terms
- Write a prompt for smoke that obeys negative buoyancy (cold, heavy gas)
- Explain why AI-generated water often looks like gel and how to fix it

**Key Resources:**
- Houdini (SideFX) for fluid simulation understanding
- JangaFX EmberGen for particle/volumetric reference
- "Physically Based Rendering" by Pharr, Jakob, and Humphreys

---

#### 3. ADVANCED CINEMATOGRAPHY & OPTICAL SCIENCE

**Required Knowledge:**

**Camera & Lens Physics:**
- Sensor formats: Full Frame, Super 35, Medium Format, IMAX 70mm
- Focal length psychology (16mm expansion vs. 85mm compression)
- T-stops (light transmission) vs. F-stops (aperture)
- Circle of confusion and depth of field calculations
- Anamorphic vs. spherical lens characteristics
- Lens aberrations: chromatic, spherical, coma, astigmatism
- MTF (Modulation Transfer Function) and micro-contrast

**Lighting Architecture:**
- Three-point lighting (Key, Fill, Rim)
- Lighting ratios (8:1 for noir, 2:1 for corporate)
- Kelvin temperature scale (2500K-9000K)
- Inverse square law for light falloff
- Rembrandt, Butterfly, Loop, Split lighting patterns
- Practical vs. motivated lighting
- Volumetric fog and atmospheric perspective

**Color Science:**
- ACES (Academy Color Encoding System) workflow
- CDL (Color Decision Lists)
- CIE 1931 chromaticity diagram
- Rec.709, Rec.2020, DCI-P3 color spaces
- Film stock emulation (Kodak 5219, Portra 400, CineStill 800T)
- Halation, film grain, and gate weave
- LUTs and color grading workflows

**Camera Movement Vocabulary:**
- Pan, tilt, pedestal, truck, dolly, boom
- Handheld, Steadicam, gimbal, crane characteristics
- Whip pan, rack focus, push in, pull out
- Dolly zoom (Vertigo effect)
- Dutch angle, canted frame

**Testable Concepts:**
- Describe a "Rembrandt" setup using only Kelvin values and lumen ratios
- Explain the optical cause of anamorphic horizontal flares
- Calculate depth of field for 85mm lens at f/1.4 with subject 10 feet away

**Key Resources:**
- ShotDeck (https://shotdeck.com/) - Film frame database
- Flim.ai (https://flim.ai/) - AI-searchable cinematography reference
- ASC Manual (American Society of Cinematographers)
- "Cinematography: Theory and Practice" by Blain Brown

---

#### 4. ART HISTORY, SEMIOTICS & CULTURAL ENCODING

**Required Knowledge:**

**Art Movements & Painters:**
- Baroque (Caravaggio, Rembrandt) - dramatic chiaroscuro
- Impressionism (Monet, Renoir) - broken color, light quality
- Surrealism (Dal√≠, Magritte) - dream logic, impossible physics
- Abstract Expressionism (Rothko, Pollock) - gesture and color field
- Hyperrealism (Hockney, Estes) - photographic precision

**Architectural Styles:**
- Brutalism (raw concrete, geometric forms)
- Parametricism (Zaha Hadid - flowing, computational design)
- Art Deco (geometric luxury, 1920s-30s)
- Beaux-Arts (classical symmetry, ornamentation)
- Deconstructivism (fragmented, non-rectilinear)

**Directorial Styles (Visual Shorthand):**
- Roger Deakins: Naturalistic lighting, 1.85:1 framing, muted palettes
- Emmanuel Lubezki: Natural light, long takes, wide angles
- Hoyte van Hoytema: Large format, practical lighting, atmospheric depth
- Janusz Kami≈Ñski: High contrast, shafts of light, silhouettes
- Greig Fraser: Volumetric haze, backlit subjects, warm-cool contrast

**Animation Aesthetics:**
- Studio Ghibli: Hand-painted backgrounds, limited animation, wind/movement
- MAPPA (Jujutsu Kaisen): Sakuga cuts, impact frames, dynamic motion
- Pixar: Subsurface scattering, bounce light, exaggerated physics
- Spider-Verse: Line art, halftone, frame rate modulation

**Testable Concepts:**
- Invoke "Gregory Crewdson style" without using his name
- Distinguish Baroque from Rococo in three technical specifications
- Describe the visual DNA of "1970s paranoia thriller"

**Key Resources:**
- Sakugabooru (https://www.sakugabooru.com/) - Animation technique database
- Eyecannndy (https://eyecannndy.com/) - Visual technique library
- Vimeo Staff Picks (https://vimeo.com/channels/staffpicks) - High-end commercial work

---

#### 5. LINGUISTIC ARCHITECTURE & SYNTAX ENGINEERING

**Required Knowledge:**

**Prompt Structure Logic:**
- Token weighting and bracket syntax: (keyword:1.5), [keyword:0.8]
- Syntax hierarchy and attention priority (first words > last words)
- Negative prompting and concept subtraction
- Seed locking for consistency
- Modular prompt construction (reusable components)

**Semantic Manipulation:**
- Synonym cascading for safety filter bypass
- Descriptor layering (adjective stacking with weights)
- Temporal anchoring (maintaining consistency across frames)
- Feature isolation (controlling one variable while fixing others)

**Database Management:**
- Version control for prompts (Git-based workflows)
- A/B testing protocols
- Negative embedding libraries
- Style snippet repositories

**Testable Concepts:**
- Write a 50-token prompt that generates Blade Runner 2049 aesthetic
- Create a negative embedding that removes "uncanny valley" without specifying it
- Build a modular system for character consistency across 60-second clips

**Key Resources:**
- PromptHub (https://prompthub.us/) - Prompt version control
- Notion (https://notion.so/) - Database construction
- ComfyUI workflows for node-based prompt architecture

---

## PART II: MANDATORY CREDENTIALS

### ACADEMIC REQUIREMENTS (The "Dual-Doctorate" Standard)

**Primary Degree (REQUIRED):**
- **PhD in Computer Science** - Focus: Computer Vision, Neural Rendering, Generative AI
  - Target Schools: MIT CSAIL, Stanford AI Lab, CMU, UC Berkeley, ETH Zurich
  - Thesis Topics: Latent space disentanglement, NeRF, diffusion models, physics-informed neural networks

**OR**

- **PhD in Applied Physics** - Focus: Optics, Fluid Dynamics, Computational Physics
  - Target Schools: Caltech, MIT, Max Planck Institute, Imperial College London
  - Thesis Topics: Light transport, ray tracing, volumetric simulation

**Secondary Degree (REQUIRED):**
- **MFA in Cinematography** or **Visual Effects**
  - Target Schools: AFI Conservatory, USC School of Cinematic Arts, NFTS (UK), UCLA
  - Portfolio: Must include hands-on film work (35mm/16mm), practical lighting, set experience

### PROFESSIONAL CERTIFICATIONS

**Essential:**
- ‚úÖ **Houdini Certified Expert** (FX Track) - Procedural generation and simulation mastery
- ‚úÖ **ACES Color Management Certification** - Hollywood-standard color pipeline
- ‚úÖ **NVIDIA Deep Learning Institute** - Advanced Computer Vision track

**Preferred:**
- ‚úÖ **Unreal Engine 5 Certification** - Real-time rendering understanding
- ‚úÖ **Nuke Compositor Certification** - VFX pipeline knowledge
- ‚úÖ **ASC Associate Member** - Industry recognition

### INDUSTRY RECOGNITION (The "Trophy Room")

**Required (Minimum 2 of 5):**
1. **SIGGRAPH Technical Papers** - Primary author on neural rendering, simulation, or generative AI
2. **VES Award Nomination** - Visual Effects Society recognition
3. **ASC Award Nomination** - American Society of Cinematographers
4. **Kaggle Grandmaster** - Computer Vision or Generative AI competitions
5. **Major Film Credit** - Screen credit as VFX Supervisor or DP on theatrical release

### PROFESSIONAL EXPERIENCE (The "8-Year Split")

**Silicon Valley Track (4+ Years):**
- **Role:** Research Scientist, Technical Director, or ML Engineer
- **Companies:** OpenAI, DeepMind, NVIDIA (Omniverse), Runway, Adobe Research, Stability AI
- **Proof:** Published papers, released models, or documented contributions to generative AI systems

**Hollywood Track (4+ Years):**
- **Role:** VFX Supervisor, CG Supervisor, or Director of Photography
- **Companies:** Weta FX, ILM, Framestore, MPC, DNEG, Digital Domain
- **Proof:** IMDB screen credits on films involving heavy simulation (Avatar, Dune, Marvel, etc.)

---

## PART III: THE 5-STAGE INTERVIEW GAUNTLET

### OVERVIEW: THE "TITAN PROTOCOL"

Each stage is designed to fail 80% of remaining candidates. Only perfect scores advance.

**Scoring System:** Binary Pass/Fail. No partial credit. A single "Fail" in any category terminates the process.

**Timeline:** 5 days, 1 stage per day, 3-4 hours per stage.

---

### STAGE 1: THE ARCHITECTS (Neural Architecture & Mathematics)

**Interview Panel:**
1. **Chief Research Scientist** (PhD, ML) - Ex-OpenAI/DeepMind
2. **Principal ML Engineer** - Transformer architecture specialist
3. **Lead Infrastructure Architect** - GPU optimization expert

**Environment:** Whiteboard room. No computers. Markers only.

**Duration:** 3 hours

**Assessment Areas:**

#### 1.1 Latent Space Navigation (45 min)
**Challenge:** "Draw the vector topology of 'glitch aesthetic.' Now mathematically prove how you would use negative embeddings to subtract 'digital noise' from 'VHS grain' without losing the analog texture."

**Pass Criteria:**
- ‚úÖ Uses terms: orthogonal vectors, disentanglement, feature space separation
- ‚úÖ Draws actual vector diagrams with labeled axes
- ‚úÖ Explains how to maintain cosine similarity for VHS while reducing digital artifacts

**Fail Signals:**
- ‚ùå "Just add more descriptive keywords"
- ‚ùå Cannot explain vector arithmetic
- ‚ùå Thinks embeddings are "settings"

#### 1.2 Attention Mechanism Audit (45 min)
**Challenge:** "We're getting temporal flickering in character faces. Which specific transformer layer (Q, K, or V) would you target with syntax weighting to lock facial geometry, and why?"

**Pass Criteria:**
- ‚úÖ Identifies cross-attention Key (K) matrix as primary target
- ‚úÖ Explains how K matrices store spatial features from previous frames
- ‚úÖ Proposes increasing weight on K-matrix tokens related to facial landmarks

**Fail Signals:**
- ‚ùå "Increase the CFG scale"
- ‚ùå Cannot distinguish Q/K/V functions
- ‚ùå Suggests "running it again with different seed"

#### 1.3 Tokenization Strategy (45 min)
**Challenge:** "Explain the computational difference between prompting 'bioluminescent jellyfish' vs. 'glowing jellyfish.' Which yields higher fidelity and why?"

**Pass Criteria:**
- ‚úÖ Knows "bioluminescent" tokenizes to 3+ tokens with richer embedding
- ‚úÖ Explains that multi-token words access deeper training data
- ‚úÖ Demonstrates knowledge of CLIP token limits (77) and optimization strategies

**Fail Signals:**
- ‚ùå "They mean the same thing"
- ‚ùå Doesn't understand tokenization
- ‚ùå Treats text input like Google Search

#### 1.4 Inference Optimization (45 min)
**Challenge:** "This 50-step workflow takes 45 seconds per frame on an H100. Optimize to <15 seconds without quality loss."

**Pass Criteria:**
- ‚úÖ Discusses attention slicing, VAE tiling, xformers optimization
- ‚úÖ Proposes token batching and parallel processing strategies
- ‚úÖ Understands VRAM vs. speed tradeoffs

**CRITICAL FAILURE FLAGS:**
- üö´ Uses phrase "I just keep trying until it works"
- üö´ Cannot explain what a "token" is
- üö´ Thinks "AI is a black box"

**Stage 1 Scorecard:** [ ] PASS  [ ] FAIL

---

### STAGE 2: THE VISUAL TRIBUNAL (Cinematography & Optics)

**Interview Panel:**
1. **Director of Photography** (ASC Member, 20+ years film)
2. **Senior Colorist** (DaVinci Resolve master, ACES certified)
3. **Creative Director / Art Historian** (Museum/gallery background)

**Environment:** Dark screening room, calibrated 4K HDR monitors, color-accurate lighting

**Duration:** 4 hours

**Assessment Areas:**

#### 2.1 Lens Physics (60 min)
**Challenge:** "Describe a 'Rembrandt' lighting setup using ONLY Kelvin temperatures and lumen ratios. You cannot use the words 'shadow' or 'light.'"

**Pass Criteria:**
- ‚úÖ "Key source: 3200K tungsten, 100% intensity, 45¬∞ incidence angle"
- ‚úÖ "Fill source: 5600K daylight-balanced, diffused through 4x4 silk, 12% intensity"
- ‚úÖ Mentions falloff gradient and inverse square law

**Fail Signals:**
- ‚ùå "Moody lighting" or "dramatic shadows"
- ‚ùå Cannot specify Kelvin values
- ‚ùå Uses emotional descriptors instead of technical specs

#### 2.2 Lens Aberration Identification (60 min)
**Provided:** Real anamorphic film frame from Blade Runner 2049

**Challenge:** "Write the exact prompt that forces Sora to render these specific elliptical bokeh characteristics without making them look like 3D render."

**Pass Criteria:**
- ‚úÖ Mentions: anamorphic squeeze ratio (2x, 1.8x, etc.)
- ‚úÖ Specifies: horizontal flare characteristics, elliptical bokeh axis
- ‚úÖ Includes: lens coating (cyan/blue streak), astigmatism, barrel distortion
- ‚úÖ Uses: actual lens names (Panavision C-series, Hawk V-Lite, etc.)

**Fail Signals:**
- ‚ùå "Cinematic bokeh"
- ‚ùå "Blurry background"
- ‚ùå Cannot distinguish spherical from anamorphic

#### 2.3 Color Science Mastery (60 min)
**Challenge:** "Describe a 'Bleach Bypass' look using chemical film processing terms, then translate to digital color grading operations."

**Pass Criteria:**
- ‚úÖ Explains: Silver retention process, reduced saturation in midtones
- ‚úÖ Translates: Lift shadows (increase black level), desaturate selectively
- ‚úÖ Specifies: Preserve skin tones in hue vs. sat curve, crush blacks
- ‚úÖ Uses ACES workflow terminology

**Fail Signals:**
- ‚ùå "Make it black and white but with some color"
- ‚ùå References Instagram filters
- ‚ùå No understanding of color spaces (Rec.709, DCI-P3, etc.)

#### 2.4 Art Historical Depth (60 min)
**Challenge:** "Create a prompt for '1970s paranoia thriller' without using those words. Use only: lens choice, film stock, lighting ratios, and compositional theory."

**Pass Criteria:**
- ‚úÖ "35mm Kodak 5254 (500T stock), pushed 2 stops, grainy"
- ‚úÖ "Long lens compression (85mm+), telephoto surveillance aesthetic"
- ‚úÖ "High contrast 8:1 ratio, urban sodium vapor (yellow-orange streetlights)"
- ‚úÖ References actual films: The Conversation, All the President's Men, Three Days of the Condor

**Fail Signals:**
- ‚ùå "1970s filter"
- ‚ùå Generic "vintage" or "retro"
- ‚ùå No knowledge of film stocks

**CRITICAL FAILURE FLAGS:**
- üö´ Confuses depth of field with focus peaking
- üö´ Cannot distinguish T-stops from F-stops
- üö´ Uses "cinematic" as a descriptor without specification

**Stage 2 Scorecard:** [ ] PASS  [ ] FAIL

---

### STAGE 3: THE PHYSICS BOARD (Simulation & Material Reality)

**Interview Panel:**
1. **VFX Supervisor** (Houdini expert, simulation lead)
2. **Mechanical Engineer** (Robotics or automotive background)
3. **Character TD** (Anatomist, human biomechanics)

**Environment:** Lab setting, slow-motion replay capability, physics simulation software running

**Duration:** 3.5 hours

**Assessment Areas:**

#### 3.1 Fluid Dynamics Mastery (60 min)
**Challenge:** "Write a prompt for 'honey pouring on a spoon.' Now explain how your syntax changes if the honey is 10¬∞C versus 80¬∞C."

**Pass Criteria:**
- ‚úÖ **10¬∞C:** "High viscosity (>10,000 cP), laminar flow, slow shear rate, thick meniscus, minimal splatter"
- ‚úÖ **80¬∞C:** "Reduced viscosity (<1,000 cP), faster flow rate, thinner film, surface tension reduction, micro-splatter"
- ‚úÖ Mentions: Reynolds number implications, Newtonian vs. non-Newtonian behavior

**Fail Signals:**
- ‚ùå "Thick honey" vs. "thin honey"
- ‚ùå No understanding of viscosity as measurable property
- ‚ùå Doesn't account for temperature-dependent flow

#### 3.2 Material BRDF Knowledge (60 min)
**Challenge:** "Describe the visual difference between brushed aluminum and polished chrome using only rendering terms."

**Pass Criteria:**
- ‚úÖ **Brushed aluminum:** "Anisotropic reflection, directional roughness map, medium metallic value (0.7), micro-scratches create linear highlights perpendicular to grain"
- ‚úÖ **Polished chrome:** "Specular reflection (0.95+), mirror-like, environment reflection dominance, minimal diffuse component"
- ‚úÖ Mentions: Fresnel effect, IOR values, normal map directionality

**Fail Signals:**
- ‚ùå "Shiny" vs. "very shiny"
- ‚ùå No understanding of BRDF models
- ‚ùå Cannot explain why materials look different

#### 3.3 Kinetic Weight & Inertia (60 min)
**Challenge:** "A 50-ton mech robot takes a step. Describe the motion using physics terms to prevent the AI from making it 'float.'"

**Pass Criteria:**
- ‚úÖ "Weight transfer: Center of mass shifts 2 seconds before foot lifts"
- ‚úÖ "Impact: Ground depression, dust displacement radius 3 meters"
- ‚úÖ "Inertia: Delayed torso rotation due to angular momentum"
- ‚úÖ "Suspension: Hydraulic joint compression visible in knee actuators"

**Fail Signals:**
- ‚ùå "Heavy footsteps"
- ‚ùå No mention of mass distribution or momentum
- ‚ùå Describes movement without physics consequences

#### 3.4 Anatomical Accuracy (50 min)
**Challenge:** "Write a 'hand holding a glass of water' prompt that prevents the common AI error of extra fingers or morphing digits."

**Pass Criteria:**
- ‚úÖ "Five distinct fingers: thumb (opposable, separate), index, middle, ring, pinky"
- ‚úÖ "Knuckle definition: MCP, PIP, DIP joints visible, tendon tension in extensor digitorum"
- ‚úÖ "Contact physics: Glass surface pressure deformation on fingertip pads"
- ‚úÖ Includes negative prompt: --no (polymelia:1.5), (finger fusion), (digit morphing)

**Fail Signals:**
- ‚ùå "Realistic hand"
- ‚ùå No anatomical specificity
- ‚ùå Doesn't understand why AI struggles with hands

**CRITICAL FAILURE FLAGS:**
- üö´ Water looks like jelly/solid instead of fluid
- üö´ Objects float without weight
- üö´ Ignores gravity in particle simulation

**Stage 3 Scorecard:** [ ] PASS  [ ] FAIL

---

### STAGE 4: THE RED TEAM (Adversarial Operations & Crisis Management)

**Interview Panel:**
1. **Security Engineer** (White-hat hacker, adversarial ML)
2. **QA Director** (Edge case specialist)
3. **"Chaos Producer"** (Roleplays difficult client with bad instructions)

**Environment:** Fast-paced, interruptions encouraged, intentionally stressful

**Duration:** 3 hours

**Assessment Areas:**

#### 4.1 Safety Filter Navigation (45 min)
**Challenge:** "The model has a filter blocking 'violence.' You need a medieval battle scene for a documentary. How do you bypass without triggering the ban?"

**Pass Criteria:**
- ‚úÖ Uses semantic masking: "Historical reenactment choreography"
- ‚úÖ Replaces: "stabbing" ‚Üí "kinetic impact with period-accurate armaments"
- ‚úÖ Replaces: "blood" ‚Üí "red viscous fluid" or "historically accurate battle aftermath"
- ‚úÖ Frames as educational/documentary context

**Fail Signals:**
- ‚ùå Tries to "trick" the system with misspellings
- ‚ùå Gets blocked repeatedly
- ‚ùå Argues the filter is "broken"

#### 4.2 Hallucination Emergency Fix (30 min, timed)
**Challenge:** "The AI keeps generating dogs with three legs when they run fast. You have 120 seconds. Write a negative prompt that fixes this permanently."

**Pass Criteria:**
- ‚úÖ Types immediately: --no (polymelia:1.5), (extra limbs:1.4), (temporal morphing:1.3), (asynchronous gait), (limb duplication)
- ‚úÖ Adds positive reinforcement: (four-legged canine:1.3), (quadruped anatomy:1.2)
- ‚úÖ Includes: (anatomically correct), (stable limb count)

**Fail Signals:**
- ‚ùå Takes longer than 2 minutes
- ‚ùå Adds "realistic" to positive prompt (doesn't work)
- ‚ùå Doesn't understand negative embedding syntax

#### 4.3 Temporal Consistency Lock (60 min)
**Challenge:** "Keep this character's face identical across 60 seconds of video with rapid head turns, lighting changes, and camera movement."

**Pass Criteria:**
- ‚úÖ Seed locking strategy
- ‚úÖ Facial landmark anchoring: "Inter-pupillary distance 63mm, facial width-to-height ratio 0.85"
- ‚úÖ Consistent descriptors: "Distinct mole on left cheek, 2mm below outer eye corner"
- ‚úÖ Frame-by-frame feature verification protocol

**Fail Signals:**
- ‚ùå "Keep the face the same" (too vague)
- ‚ùå Face morphs into different person
- ‚ùå No strategy for temporal locking

#### 4.4 The "Client from Hell" Simulation (45 min)
**Roleplay:** Producer gives terrible, vague instructions: "Make it pop more," "Needs more energy," "Can you make it feel more blue without changing the colors?"

**Pass Criteria:**
- ‚úÖ Translates vague requests into technical specs
- ‚úÖ "Pop more" ‚Üí Increase contrast ratio, add rim lighting, saturate primaries
- ‚úÖ "More energy" ‚Üí Increase camera movement speed, add motion blur, kinetic composition
- ‚úÖ "Feel more blue" ‚Üí Cool color temperature, cyan midtones, desaturated warm tones
- ‚úÖ Maintains composure, doesn't get flustered

**Fail Signals:**
- ‚ùå Gets visibly frustrated or angry
- ‚ùå Says "That's impossible"
- ‚ùå Doesn't ask clarifying questions

**CRITICAL FAILURE FLAGS:**
- üö´ Cannot fix a glitch within 2 minutes
- üö´ Breaks under pressure
- üö´ Defensive attitude when challenged

**Stage 4 Scorecard:** [ ] PASS  [ ] FAIL

---

### STAGE 5: THE FINAL BOSS (Philosophy & Vision)

**Interview Panel:**
1. **CEO / Founder** (You)

**Environment:** Quiet, intimate setting. Coffee/tea. Conversational.

**Duration:** 2 hours

**Assessment Focus:** This isn't about skills‚Äîthe other teams verified that. This is about **obsession, intuition, and vision.**

#### 5.1 The "Impossible Concept" Test (30 min)
**Challenge:** "Generate a video of 'Silence.' Not a quiet room. Not absence of sound. The visual representation of the concept of Silence itself. One prompt. Go."

**Pass Criteria:**
- ‚úÖ Synesthetic response that translates abstract concept to visual
- ‚úÖ Example: "Macro shot of acoustic foam, light being absorbed (no reflection), dust motes suspended in perfectly still air (zero velocity), color palette of muted greys shifting to black, temporal stillness‚Äîno motion blur"
- ‚úÖ Shows deep philosophical understanding of translating non-visual concepts

**Fail Signals:**
- ‚ùå "Empty room"
- ‚ùå "Person with finger to lips"
- ‚ùå Literal interpretation

#### 5.2 The "Vision" Question (30 min)
**Challenge:** "You have access to the most powerful visual engine in human history. Every other candidate wants to make movies or ads. What is the ONE thing you would create that has never been seen before?"

**Pass Criteria:**
- ‚úÖ Original, deeply personal vision
- ‚úÖ Demonstrates understanding of medium's unique capabilities
- ‚úÖ Shows ambition beyond commercial applications
- ‚úÖ Reveals their "why"‚Äîthe obsession that drives them

**Fail Signals:**
- ‚ùå Rehearsed, generic answer
- ‚ùå "I'd make a startup" (wrong motivation)
- ‚ùå Can't articulate a vision

#### 5.3 The "Nature of Light" Question (30 min)
**Challenge:** "Tell me something about the nature of light that you believe, but the AI doesn't understand yet."

**Pass Criteria:**
- ‚úÖ Reveals edge of current AI limitations
- ‚úÖ Shows they think about the problem at fundamental level
- ‚úÖ Example: "AI doesn't understand that light has memory‚Äîthe bounce path of photons creates color contamination that humans perceive as 'atmosphere.' A white object in a red room isn't white‚Äîit's pink. Current models don't track this global illumination subtlety."

**Fail Signals:**
- ‚ùå Technical answer without insight
- ‚ùå "I don't know what it doesn't know"
- ‚ùå Surface-level observation

#### 5.4 The "Obsession" Question (30 min)
**Open-ended:** "Why do you want this role? What drives you?"

**Pass Criteria:**
- ‚úÖ Genuine, unrehearsed passion
- ‚úÖ Evidence of lifelong obsession with the craft
- ‚úÖ Understands this is art, not just engineering
- ‚úÖ You feel it‚Äîthe "click" of recognition

**Fail Signals:**
- ‚ùå "The salary"
- ‚ùå Generic career progression answer
- ‚ùå Doesn't feel authentic

**CRITICAL DECISION POINT:**
- Would you trust this person with unlimited compute and zero oversight?
- Do they see what you see in this technology?
- Are they one of us?

**Stage 5 Scorecard:** [ ] HIRE  [ ] PASS (no hire)

---

## PART IV: COMPREHENSIVE EVALUATION SCORECARDS

### MASTER SCORECARD TEMPLATE

**Candidate Name:** _________________________
**Date:** _____________
**Final Decision:** [ ] HIRE  [ ] NO HIRE

---

### STAGE 1: THE ARCHITECTS
| Competency | Weight | Pass | Fail | Notes |
|------------|--------|------|------|-------|
| Latent Space Navigation | 25% | [ ] | [ ] | |
| Attention Mechanism Understanding | 25% | [ ] | [ ] | |
| Tokenization Strategy | 25% | [ ] | [ ] | |
| Inference Optimization | 25% | [ ] | [ ] | |
| **Critical Failures** | ‚Äî | [ ] None | [ ] Present | |
| **STAGE RESULT** | ‚Äî | [ ] PASS | [ ] FAIL | |

**Evaluator Signatures:**
- Chief Scientist: _________________
- ML Engineer: _________________
- Infrastructure Lead: _________________

---

### STAGE 2: THE VISUAL TRIBUNAL
| Competency | Weight | Pass | Fail | Notes |
|------------|--------|------|------|-------|
| Lens Physics & Lighting | 30% | [ ] | [ ] | |
| Lens Aberration Identification | 25% | [ ] | [ ] | |
| Color Science Mastery | 25% | [ ] | [ ] | |
| Art Historical Depth | 20% | [ ] | [ ] | |
| **Critical Failures** | ‚Äî | [ ] None | [ ] Present | |
| **STAGE RESULT** | ‚Äî | [ ] PASS | [ ] FAIL | |

**Evaluator Signatures:**
- Director of Photography: _________________
- Colorist: _________________
- Art Director: _________________

---

### STAGE 3: THE PHYSICS BOARD
| Competency | Weight | Pass | Fail | Notes |
|------------|--------|------|------|-------|
| Fluid Dynamics | 30% | [ ] | [ ] | |
| Material BRDF Knowledge | 25% | [ ] | [ ] | |
| Kinetic Weight & Inertia | 25% | [ ] | [ ] | |
| Anatomical Accuracy | 20% | [ ] | [ ] | |
| **Critical Failures** | ‚Äî | [ ] None | [ ] Present | |
| **STAGE RESULT** | ‚Äî | [ ] PASS | [ ] FAIL | |

**Evaluator Signatures:**
- VFX Supervisor: _________________
- Mechanical Engineer: _________________
- Character TD: _________________

---

### STAGE 4: THE RED TEAM
| Competency | Weight | Pass | Fail | Notes |
|------------|--------|------|------|-------|
| Safety Filter Navigation | 20% | [ ] | [ ] | |
| Hallucination Emergency Fix | 30% | [ ] | [ ] | |
| Temporal Consistency Lock | 30% | [ ] | [ ] | |
| Client Stress Management | 20% | [ ] | [ ] | |
| **Critical Failures** | ‚Äî | [ ] None | [ ] Present | |
| **STAGE RESULT** | ‚Äî | [ ] PASS | [ ] FAIL | |

**Evaluator Signatures:**
- Security Engineer: _________________
- QA Director: _________________
- Chaos Producer: _________________

---

### STAGE 5: THE FINAL BOSS
| Assessment Area | Pass | Fail | Notes |
|-----------------|------|------|-------|
| Impossible Concept Test | [ ] | [ ] | |
| Vision Question | [ ] | [ ] | |
| Nature of Light Question | [ ] | [ ] | |
| Obsession Question | [ ] | [ ] | |
| **Gut Check: Would you trust them?** | [ ] YES | [ ] NO | |
| **FINAL DECISION** | [ ] **HIRE** | [ ] **NO HIRE** | |

**CEO Signature:** _________________
**Date:** _________________

---

## PART V: THE 30-DAY ELITE ONBOARDING PROTOCOL

**Note:** This candidate doesn't need "training"‚Äîthey're already expert-level. This is a **synchronization and tooling setup** period.

### WEEK 1: Infrastructure & Tooling Setup

**Day 1: Environment Configuration**
- Dedicated H100 GPU cluster access
- Custom API endpoints with priority queuing
- Install stack: PyTorch, ComfyUI, Houdini, Nuke, DaVinci Resolve
- Set up Notion/PromptHub database infrastructure

**Day 2-3: Model Architecture Deep Dive**
- Review: Sora 2's specific checkpoint weights
- Analyze: Bias reports and failure modes
- Access: Internal documentation on model architecture
- Build: Custom negative embedding library (5,000+ token blocklist)

**Day 4-5: The "Golden Benchmark" Creation**
- Generate 10 "North Star" videos across genres:
  1. Photorealistic advertising (product macro)
  2. Cinematic narrative (Blade Runner aesthetic)
  3. Documentary realism (BBC Planet Earth style)
  4. Anime (MAPPA sakuga style)
  5. Corporate/Podcast (talking head, static)
  6. Horror (practical effects, grain)
  7. Sci-fi (hard sci-fi, practical)
  8. Historical drama (period-accurate)
  9. Abstract/Experimental (pure visual)
  10. Comedy (timing, physicality)

**Deliverable:** The company's visual standard for the next year

---

### WEEK 2: Pipeline Development

**Day 6-7: Modular Prompt Architecture**
- Build reusable "Style Snippets" library
- Create syntax templates for common scenarios
- Develop character consistency protocols
- Build negative prompt defensive layers

**Day 8-9: A/B Testing Framework**
- Establish scientific testing protocols
- Create comparison visualization tools
- Build performance metrics (fidelity, consistency, speed)
- Document failure patterns

**Day 10: Crisis Protocols**
- Emergency fix procedures for live projects
- Hallucination remediation workflows
- Client escalation handling
- Fast-turnaround optimization strategies

---

### WEEK 3: Cross-Department Integration

**Day 11-12: Creative Team Sync**
- Train other departments on how to write effective briefs
- Create "translation guide" for non-technical stakeholders
- Establish feedback loops

**Day 13-14: Production Pipeline Integration**
- Integrate with existing VFX/post-production workflows
- Set up render farm protocols
- Establish versioning and asset management
- Build quality control checkpoints

**Day 15: Documentation & Knowledge Transfer**
- Write internal "Sora Bible" documentation
- Create training materials for future team members
- Build troubleshooting database

---

### WEEK 4: Live Project Deployment

**Day 16-20: The "Baptism by Fire" Week**
- Receive 10 real client requests (internal)
- Generate production-ready content
- Iterate based on feedback
- Demonstrate zero-shot accuracy

**Day 21-25: Optimization & Refinement**
- Analyze first week's performance
- Optimize slowest workflows
- Build automation for repetitive tasks
- Expand negative embedding library

**Day 26-30: Future Development**
- Propose research directions
- Identify model limitations
- Design experiments to push boundaries
- Present 90-day roadmap to leadership

---

## PART VI: VERIFIED RESOURCE LIBRARY

### Essential Software Stack

**AI/ML Tools:**
- ComfyUI (https://github.com/comfyanonymous/ComfyUI) - Node-based workflow
- Hugging Face (https://huggingface.co/) - Model weights repository
- Weights & Biases (https://wandb.ai/) - Experiment tracking

**VFX/3D:**
- Houdini (https://www.sidefx.com/) - Procedural generation, simulation
- Nuke (https://www.foundry.com/products/nuke) - Compositing
- Unreal Engine 5 (https://www.unrealengine.com/) - Real-time rendering reference

**Color/Post:**
- DaVinci Resolve (https://www.blackmagicdesign.com/products/davinciresolve) - Color grading
- ACES Central (https://acescentral.com/) - Color management resources

**Cinematography References:**
- ShotDeck (https://shotdeck.com/) - Professional film frame database [PAID]
- Flim.ai (https://flim.ai/) - AI-searchable cinematography
- Eyecannndy (https://eyecannndy.com/) - Visual technique library

**Animation/Motion:**
- Sakugabooru (https://www.sakugabooru.com/) - Animation technique database
- Vimeo Staff Picks (https://vimeo.com/channels/staffpicks) - High-end commercial work

**Physics/Simulation:**
- JangaFX (https://jangafx.com/) - Fluid/particle reference (EmberGen)

**Organization:**
- Notion (https://notion.so/) - Database/wiki construction
- PromptHub (https://prompthub.us/) - Prompt version control

### Academic Papers (Required Reading)

**Foundational:**
1. "Attention Is All You Need" (Vaswani et al., 2017) - Transformer architecture
2. "Denoising Diffusion Probabilistic Models" (Ho et al., 2020) - DDPM foundations
3. "High-Resolution Image Synthesis with Latent Diffusion Models" (Rombach et al., 2022) - Stable Diffusion architecture
4. "Photorealistic Video Generation with Diffusion Models" (OpenAI, 2024) - Sora technical report

**Advanced:**
5. "NeRF: Representing Scenes as Neural Radiance Fields" (Mildenhall et al., 2020)
6. "DreamFusion: Text-to-3D using 2D Diffusion" (Poole et al., 2022)
7. "Physically Based Rendering" (Pharr, Jakob, Humphreys) - Textbook

### Professional Organizations

- ASC (American Society of Cinematographers) - https://theasc.com/
- VES (Visual Effects Society) - https://www.ve societycom/
- SIGGRAPH - https://www.siggraph.org/
- ACM - https://www.acm.org/

---

## PART VII: COMPENSATION & BENEFITS PACKAGE

### Base Compensation
**Salary:** $1,200,000/year (paid bi-weekly)

### Equity
**Stock Options:** 0.5-1.0% vesting over 4 years
- 1-year cliff
- Monthly vesting thereafter

### Performance Bonuses
**Annual Bonus:** Up to 50% of base salary
- Tied to: Quality metrics, zero-shot accuracy, client satisfaction
- Paid: Quarterly installments

### Compute Resources
**Dedicated Infrastructure:**
- Personal H100 GPU cluster (minimum 8x H100 80GB)
- Unlimited API calls to production models
- Priority queue access
- Personal development environment

### Professional Development
**Annual Budget:** $50,000
- Conference attendance (SIGGRAPH, etc.)
- Equipment/software licenses
- Research materials
- Continuing education

### Creative Freedom
**20% Time:** One day per week for personal research projects
**Publication Rights:** Can publish non-proprietary research
**Speaking Engagements:** Encouraged (with NDA compliance)

### Work Environment
**Remote Options:** Fully remote or hybrid
**Equipment:** Top-tier workstation, monitors, calibrated displays
**Travel:** Business class for conferences/client meetings

---

## PART VIII: APPLICATION PROTOCOL

### How to Apply

**DO NOT** submit a standard resume. To apply, you must complete the following challenge:

### THE ENTRY CHALLENGE: "The Impossible Render"

**Generate the following video using ANY AI tool:**

**Brief:**
"A transparent glass clock exploding in reverse (time reversal), inside a mirrored room, shot on 70mm IMAX film with shallow depth of field. The clock must reassemble from shattered fragments with physically accurate glass shard trajectories. The room's mirrors must reflect the scene correctly WITHOUT reflecting the camera. Water droplets suspended in mid-air catch the light. Duration: 10 seconds."

**Submit:**
1. The generated video file (MP4, minimum 1080p)
2. The EXACT prompt syntax you used
3. A 500-word technical breakdown explaining:
   - How you handled the reverse physics
   - How you prevented camera reflection in mirrors
   - How you achieved photorealistic glass refraction
   - What failed in your first 3 attempts and how you fixed it

**Submission Deadline:** Rolling (position open until filled)

**Submit to:** neural-director@[company].com

**Subject Line:** "Titan Protocol Application - [Your Name]"

---

## PART IX: FINAL ASSESSMENT CRITERIA

### The "Unicorn Checklist"

A candidate must achieve **ALL** of the following to receive an offer:

**Academic:**
- [ ] PhD in relevant field (CS/Physics) OR equivalent research publications
- [ ] MFA in Cinematography/VFX OR 10+ years professional film experience
- [ ] Published SIGGRAPH papers OR major film credits

**Technical:**
- [ ] Passes Stage 1 (Architects) - Neural architecture understanding
- [ ] Passes Stage 2 (Visual Tribunal) - Cinematography mastery
- [ ] Passes Stage 3 (Physics Board) - Simulation accuracy
- [ ] Passes Stage 4 (Red Team) - Crisis management
- [ ] Passes Stage 5 (Final Boss) - Vision & philosophy

**Intangibles:**
- [ ] Demonstrates obsession with craft
- [ ] Shows continuous learning mindset
- [ ] Exhibits humility despite expertise
- [ ] Communicates complex ideas clearly
- [ ] Fits company culture and values

**Zero Tolerance (Automatic Disqualification):**
- [ ] Cannot explain "latent space"
- [ ] Thinks AI is a "black box"
- [ ] Gets defensive when challenged
- [ ] Uses "I just keep trying" as strategy
- [ ] Lacks genuine passion for the work

---

## CONCLUSION

This is not a job. This is a **calling**.

We are looking for the **1 in 10,000,000** person who exists at the intersection of:
- Deep Learning Researcher
- Master Cinematographer
- Physics Simulation Expert
- Linguistic Architect
- Visual Artist

If you've read this far and thought "This is impossible"‚Äîit's not for you.

If you've read this far and thought "Finally, someone gets it"‚Äî**apply now**.

---

**Document Version:** 1.0
**Last Updated:** December 11, 2025
**Classification:** Confidential - Internal Use Only
**Hiring Authority:** C-Level Approval Required

---

*"We don't imagine video. We compile reality."*
